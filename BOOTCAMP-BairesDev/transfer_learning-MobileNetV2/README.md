# Projeto: Classificacao de Frutas com Transfer Learning (MobileNetV2)

## üìå Sobre o Projeto
Este projeto utiliza **Transfer Learning** com a arquitetura **MobileNetV2** para classificar imagens de frutas: **Araticum** e **Fruta do Conde**. O modelo √© treinado com um dataset pequeno, usando t√©cnicas de **aumento de dados** (Data Augmentation) e **ajuste fino** (Fine-Tuning) para melhorar a generaliza√ß√£o.

## üìÇ Estrutura do Projeto
```
Projeto_Transfer_Learning/
‚îú‚îÄ‚îÄ conjunto_dados/          # Cont√©m os datasets de treino, valida√ß√£o e teste
‚îÇ   ‚îú‚îÄ‚îÄ treino/
‚îÇ   ‚îú‚îÄ‚îÄ validacao/
‚îÇ   ‚îú‚îÄ‚îÄ teste/
|
‚îú‚îÄ‚îÄ img/                     # Imagens
‚îú‚îÄ‚îÄ modelos/                 # Diret√≥rio para salvar os modelos treinados
‚îú‚îÄ‚îÄ scripts/                 # Cont√©m os scripts do projeto
‚îú‚îÄ‚îÄ README.md                # Documenta√ß√£o do projeto
```
O projeto est√° organizado nos seguintes m√≥dulos:

- `carregar.py`: Respons√°vel pelo carregamento e pr√©-processamento das imagens.
- `chamadas.py`: Define os callbacks utilizados no treinamento do modelo.
- `constantes.py`: Cont√©m defini√ß√µes como caminhos dos diret√≥rios, hiperpar√¢metros e classes do modelo.
- `graficos.py`: Fun√ß√µes para visualiza√ß√£o de m√©tricas e resultados.
- `modelo.py`: Implementa√ß√£o do modelo MobileNetV2 e do ajuste fino.
- `main.py`: Script principal para execu√ß√£o do modelo.

## üõ†Ô∏è Tecnologias Utilizadas
- **TensorFlow / Keras**: Para construir e treinar a rede neural
- **MobileNetV2**: Modelo pr√©-treinado usado para Transfer Learning
- **tf.data.Dataset**: Para otimizar o carregamento das imagens
- **Matplotlib e Seaborn**: Para visualiza√ß√£o dos resultados e an√°lise
- **Scikit-learn**: Para c√°lculo da matriz de confus√£o
- **Python 3.8+**

## Conjunto de Dados
Uma pequena amostra do conjunto de dados.

<p>
<center>

![dataset](img/dataset1.png)
</center>
</p>

## üèãÔ∏è Treinamento do Modelo
O modelo foi treinado em duas etapas:

### 1. Treinamento do Modelo Base

Inicialmente, a MobileNetV2 foi utilizada como extratora de caracter√≠sticas, mantendo suas camadas convolucionais congeladas. Apenas o classificador foi treinado nesta fase.

**Conjuntos de Dados**
 - Treinamento: 180 imagens
 - Valida√ß√£o: 60 imagens
 - Teste: 60 imagens

**Desempenho do Modelo Base:**

Inicialmente, o modelo apresentou uma acur√°cia de 0.6833, com uma perda de 0.6260 no conjunto de teste. Esses valores indicam um desempenho moderado, mas ainda distante de uma classifica√ß√£o ideal.

A an√°lise das m√©tricas por classe revela um desbalanceamento na capacidade de reconhecimento entre as categorias:

 - **Araticum**, a precision foi de 0.79, mas o recall baixo (0.50) sugere que muitos exemplos dessa classe foram classificados incorretamente.
 - **Fruta do Conde**, a precision foi menor (0.63), mas o recall elevado (0.87) indica que a classe foi bem capturada, embora com maior incid√™ncia de falsos positivos.

O F1-Score, m√©trica que equilibra precision e recall, reflete essa disparidade: 0.61 para Araticum e 0.73 para Fruta do Conde. Al√©m disso, a AUC de 0.74 na curva ROC confirma um desempenho razo√°vel, mas com espa√ßo para melhorias.

O modelo base apresenta um overfitting moderado, o que sugere que o ajuste pode ter ocorrido de forma limitada e que melhorias na regulariza√ß√£o, aumento de dados ou ajustes nos hiperpar√¢metros poderiam ser ben√©ficos.

### 2. Ajuste Fino (Fine-Tuning)

Ap√≥s o primeiro treinamento, algumas camadas convolucionais da MobileNetV2 foram descongeladas e treinadas com uma taxa de aprendizado reduzida para melhor adapta√ß√£o ao dataset.

**Resultados do ajuste fino:**

O ajuste fino resultou em melhorias expressivas:

 - A acur√°cia aumentou para 0.7667, indicando uma maior capacidade do modelo em realizar predi√ß√µes corretas.
 - A perda diminuiu para 0.5077, evidenciando um melhor ajuste aos dados de teste.
 - A AUC subiu para 0.90, sugerindo que o modelo aprimorado consegue distinguir melhor entre as classes.

Nas m√©tricas de classifica√ß√£o por classe:

- **Araticum**: a precision subiu para 0.83 e o recall para 0.67, reduzindo os erros de classifica√ß√£o desta classe.
- **Fruta do Conde**: a precision aumentou para 0.72, enquanto o recall permaneceu alto em 0.87, indicando que o modelo manteve uma forte capacidade de identifica√ß√£o dessa classe.

A m√©dia macro das m√©tricas tamb√©m apresentou crescimento (precision: 0.78, recall: 0.77, F1-Score: 0.76), confirmando um equil√≠brio geral aprimorado.

Entretanto, observa-se um aumento no overfitting, o que sugere que o modelo pode estar se ajustando excessivamente ao conjunto de treinamento. Esse fen√¥meno pode limitar sua generaliza√ß√£o para novos dados, tornando necess√°ria uma an√°lise mais aprofundada das estrat√©gias de regulariza√ß√£o, como:

- Aumento do conjunto de dados, para reduzir a depend√™ncia de padr√µes espec√≠ficos.
- Uso de t√©cnicas de data augmentation, que podem gerar varia√ß√µes nas imagens sem adicionar novos exemplos reais.
- Regulariza√ß√£o com dropout, caso j√° esteja sendo usado, pode ser ajustado para valores mais adequados.
- Fine-tuning mais controlado, talvez congelando mais camadas iniciais para evitar um aprendizado excessivamente espec√≠fico do conjunto de treino.

<p>
<center>

![hist](img/histfinal.png)
</center>
</p>

**Matriz de Confus√£o:** O modelo demonstrou uma boa capacidade de diferencia√ß√£o entre as classes, mas ainda apresenta dificuldades na classifica√ß√£o da classe Araticum.

<p>
<center>

![conf](img/confT.JPG)
</center>
</p>

**Curva ROC:** A √°rea sob a curva (AUC) apresentou um valor pr√≥ximo de **0.90**, ap√≥s o ajuste fino indicando um bom desempenho geral.

<p>
<center>

![roc](img/rocT.JPG)
</center>
</p>

## üìä Visualiza√ß√£o de exemplos classificados corretamente e incorretamente.

<p>
<center>

![transf](img/certoT.JPG)
![trans1](img/erradoT.JPG)
</center>
</p>


## üìå Conclus√£o

O ajuste fino demonstrou uma melhora significativa na acur√°cia, precis√£o e capacidade de discrimina√ß√£o do modelo MobileNetV2 para a tarefa de classifica√ß√£o de Araticum e Fruta Do Conde. O ganho de AUC para 0.90 destaca uma evolu√ß√£o substancial na performance do modelo, tornando-o mais confi√°vel para a aplica√ß√£o desejada.

Contudo, o aumento do overfitting exige aten√ß√£o. Estrat√©gias para aumentar a robustez do modelo, como data augmentation e ajustes na regulariza√ß√£o, podem ser consideradas para melhorar a generaliza√ß√£o sem comprometer o desempenho.

De modo geral, os resultados indicam um avan√ßo s√≥lido, e com refinamentos adicionais, o modelo pode alcan√ßar uma performance ainda mais consistente e confi√°vel.

Este projeto pode ser expandido para classificar novas categorias de frutas ou ser integrado a sistemas de reconhecimento visual.

---

## üîß Como Executar o Projeto
### 1Ô∏è‚É£ Instalar as Depend√™ncias
```bash
pip install tensorflow matplotlib numpy seaborn scikit-learn
```

### 2Ô∏è‚É£ Configurar e Rodar o Treinamento
Execute o script principal para treinar o modelo:
```bash
python main.py
```
ou execulte o notebook `rodar_script_main.ipynb`

---
